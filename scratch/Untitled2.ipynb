{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "104e0333-0c5e-4c9d-8b26-5ff9d624251b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  1.10 ; cuda:  cu113\n"
     ]
    }
   ],
   "source": [
    "# library imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 120000000\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# local imports\n",
    "from resnet_helper_functions import create_datasets, create_dataloaders, train_model\n",
    "\n",
    "# torch parameters being used\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8698aadf-adcf-474f-9324-d9e943eba288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Resnet Config File Read Successfully.\n",
      "INFO:root:Train, Validation and Test Datasets Created Successfully.\n",
      "INFO:root:Train, Validation and Test Dataloaders Created Successfully.\n",
      "INFO:root:Model Loaded Successfully.\n",
      "INFO:root:Device cuda:0 Being Used.\n",
      "INFO:root:Started Training The Model.\n"
     ]
    }
   ],
   "source": [
    "# read in config file\n",
    "with open('resnet_config.json') as f:\n",
    "    config = json.load(f)\n",
    "    logging.info('Resnet Config File Read Successfully.')\n",
    "\n",
    "# create datasets and dataloaders\n",
    "train_dataset, val_dataset, test_dataset, class_names, num_classes = create_datasets(config[\"data_dir\"], config[\"train_perc\"], config[\"val_perc\"], config[\"test_perc\"])\n",
    "logging.info('Train, Validation and Test Datasets Created Successfully.')\n",
    "\n",
    "dataloaders, dataset_sizes = create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=config[\"batch_size\"], num_workers = config[\"num_workers\"])\n",
    "logging.info('Train, Validation and Test Dataloaders Created Successfully.')\n",
    "\n",
    "# instantiate pre-trained resnet\n",
    "#net = torch.hub.load('pytorch/vision', config[\"pretrained_model_to_use\"], weights=config[\"weights_to_use\"])\n",
    "net = torchvision.models.resnet18(pretrained=True)\n",
    "logging.info('Model Loaded Successfully.')\n",
    "\n",
    "# shut off autograd for all layers to freeze model so the layer weights are not trained\n",
    "if config[\"freeze_pretrained_model\"]:\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# get the number of inputs to final FC layer\n",
    "num_ftrs = net.fc.in_features\n",
    "\n",
    "# replace existing FC layer with a new FC layer having the same number of inputs and num_classes outputs\n",
    "net.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# cross entropy loss combines softmax and nn.NLLLoss() in one single class.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.Adam(net.fc.parameters(), lr=0.001)\n",
    "\n",
    "# learning rate scheduler - not using as we used adam optimizer\n",
    "lr_scheduler = None\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f'Device {device} Being Used.')\n",
    "\n",
    "# train the model\n",
    "model_dir = config[\"model_dir\"]\n",
    "num_epochs = config[\"num_epochs\"]\n",
    "\n",
    "logging.info('Started Training The Model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cabc096-2287-4cbb-83e9-8e7a8ca4c6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7faec413eee0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f6194c-b5be-47dd-8b3e-9201fc351d8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 363, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torchvision/datasets/folder.py\", line 234, in __getitem__\n    sample = self.transform(sample)\nTypeError: 'dict' object is not callable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m dataloaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(inputs, labels)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1203\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1229\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1229\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torch/_utils.py:434\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 363, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"/hpc/group/rescomp/sg623/miniconda3/envs/cv_540/lib/python3.8/site-packages/torchvision/datasets/folder.py\", line 234, in __getitem__\n    sample = self.transform(sample)\nTypeError: 'dict' object is not callable\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in dataloaders['train']:\n",
    "    print(inputs, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac48695-29f8-40ed-849b-8dd7cc92a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = train_model(model = net, model_dir = model_dir, criterion = criterion, optimizer = optimizer, dataloaders = dataloaders, dataset_sizes = dataset_sizes, scheduler = lr_scheduler, device = device, num_epochs = num_epochs)\n",
    "\n",
    "# test the model\n",
    "#test_model(model = net, test_dataset = test_dataset, device = device)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "run_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9d76258-d9ac-4937-824e-24c76f7bc900",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"abc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0774b648-ad5f-45b6-844a-6fb96075928a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abc'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f6850-b8fb-469e-a54d-d700a5650c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_540",
   "language": "python",
   "name": "cv_540"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
